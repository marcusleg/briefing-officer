# Briefing Officer

AI summaries for your favorite news feeds.

## Prerequisites

- An OpenAI API-compatible Large Language Model (LLM) or LLM Proxy (e.g.
  [LiteLLM](https://github.com/BerriAI/litellm))

## Getting Started

```
docker run -it --rm \
  -e DATABASE_URL=file:../data/database.sqlite \
  -e OPENAI_API_URL=http://localhost:4000 \
  -e OPENAI_API_KEY=lorem-ipsum \
  -p 3000:3000 \
  ghcr.io/marcusleg/briefing-officer:unstable
```

## Dependency documentation

To learn more about dependencies, take a look at the following resources:

- [Next.js](https://nextjs.org/docs)
- [Prisma ORM](https://www.prisma.io/docs/orm)
- [Tailwind CSS](https://tailwindcss.com/docs/installation)
- [shadcn/ui](https://ui.shadcn.com/docs)
- [Lucide Icons](https://lucide.dev/icons/)

## Architecture Decisions

- Use types generated by Prisma where possible.
  - We choose to accept tight coupling with the database schema to eliminate
    the  
    need for a translation layer between database objects and
    application-specific types, resulting in less code.
- Pass complete Prisma objects to functions rather than individual properties.
  - This improves maintainability and future-proofs the code by avoiding the
    need to update function signatures when new properties are needed. It also
    reduces coupling between functions and specific object properties, making
    the code more flexible and easier to modify.
